{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMuVZWK2HeQV+pjMnE5yHGh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7ba876e64089493a99599bed9ccf6cc0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_833a6bd4e7314b669eb054aff23d9ebb","IPY_MODEL_87d10b37f9574ba8a8cecf6b800cb8ef"],"layout":"IPY_MODEL_79d274dbe66d40af9f81b4fc2ff8277d"}},"833a6bd4e7314b669eb054aff23d9ebb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"epoch:   0%","description_tooltip":null,"layout":"IPY_MODEL_fa1b6b3d99b24ba5a6b8f606a5e86af0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45db43ce1ddb47cda541d2f462c51237","value":0}},"87d10b37f9574ba8a8cecf6b800cb8ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3197f7fe2a24cb7bc212886866ee1d6","placeholder":"​","style":"IPY_MODEL_b3503afdf2274796b2d701223b7b04f4","value":" 0/1 [01:04&lt;?, ?it/s]"}},"79d274dbe66d40af9f81b4fc2ff8277d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa1b6b3d99b24ba5a6b8f606a5e86af0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45db43ce1ddb47cda541d2f462c51237":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"d3197f7fe2a24cb7bc212886866ee1d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3503afdf2274796b2d701223b7b04f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b6ba7505a294947a0818510ac1f9b6c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72a6045fae544b06aaf3fd4c996d6d7a","IPY_MODEL_c3b43a4839b94b8bb3420af86cc43081"],"layout":"IPY_MODEL_5e79f32871b147719b9cee2501d28fc1"}},"72a6045fae544b06aaf3fd4c996d6d7a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"train:   0%","description_tooltip":null,"layout":"IPY_MODEL_45e5a82e70574f85a366dd71f34cf9e4","max":71779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1729ab4e39fc4e3c9bc04554b8ff0964","value":1}},"c3b43a4839b94b8bb3420af86cc43081":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c371c5f5188a4371a71a955ef3a7c8f4","placeholder":"​","style":"IPY_MODEL_c68ce677df80410792e71b6909122d6a","value":" 1/71779 [01:00&lt;247:58:06, 12.44s/it]"}},"5e79f32871b147719b9cee2501d28fc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45e5a82e70574f85a366dd71f34cf9e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1729ab4e39fc4e3c9bc04554b8ff0964":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"c371c5f5188a4371a71a955ef3a7c8f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c68ce677df80410792e71b6909122d6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3NblQMJBgzGr","executionInfo":{"status":"ok","timestamp":1619812892397,"user_tz":-180,"elapsed":24328,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"a79bdf0e-011f-424f-d287-555ae4a13a4a"},"source":["from torchinfo import summary\n","from transformers import PegasusTokenizer, PegasusTokenizerFast, PegasusModel, PegasusForConditionalGeneration, PegasusConfig\n","\n","pegasus_model = PegasusForConditionalGeneration.from_pretrained(\"sshleifer/distill-pegasus-cnn-16-4\")\n","summary(pegasus_model)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["=====================================================================================\n","Layer (type:depth-idx)                                       Param #\n","=====================================================================================\n","├─PegasusModel: 1-1                                          --\n","|    └─Embedding: 2-1                                        98,409,472\n","|    └─PegasusEncoder: 2-2                                   --\n","|    |    └─Embedding: 3-1                                   (recursive)\n","|    |    └─PegasusSinusoidalPositionalEmbedding: 3-2        (1,048,576)\n","|    |    └─ModuleList: 3-3                                  201,539,584\n","|    |    └─LayerNorm: 3-4                                   2,048\n","|    └─PegasusDecoder: 2-3                                   --\n","|    |    └─Embedding: 3-5                                   (recursive)\n","|    |    └─PegasusSinusoidalPositionalEmbedding: 3-6        (1,048,576)\n","|    |    └─ModuleList: 3-7                                  67,186,688\n","|    |    └─LayerNorm: 3-8                                   2,048\n","├─Linear: 1-2                                                98,409,472\n","=====================================================================================\n","Total params: 467,646,464\n","Trainable params: 465,549,312\n","Non-trainable params: 2,097,152\n","====================================================================================="]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ieIaREkXYBb8","executionInfo":{"status":"ok","timestamp":1619813138748,"user_tz":-180,"elapsed":2277,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"07e5c909-c16b-44f2-eb1a-2a94173f85ee"},"source":["PegasusTokenizer.from_pretrained(\"sshleifer/distill-pegasus-cnn-16-4\").vocab_size"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["96103"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H6QjQ9yYgzEa","executionInfo":{"status":"ok","timestamp":1619813040608,"user_tz":-180,"elapsed":13880,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"62a72155-3e1b-40f1-a7e4-57dc56d04bf2"},"source":["configuration = PegasusConfig(d_model=768, vocab_size=tokenizer.vocab_size, \n","                              encoder_layers=8, decoder_layers=8, \n","                              encoder_attention_heads=12, decoder_attention_heads=12,\n","                              decoder_ffn_dim=3072, encoder_ffn_dim=3072)\n","model = PegasusForConditionalGeneration(configuration)\n","configuration = model.config\n","summary(model)"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["=====================================================================================\n","Layer (type:depth-idx)                                       Param #\n","=====================================================================================\n","├─PegasusModel: 1-1                                          --\n","|    └─Embedding: 2-1                                        73,807,104\n","|    └─PegasusEncoder: 2-2                                   --\n","|    |    └─Embedding: 3-1                                   (recursive)\n","|    |    └─PegasusSinusoidalPositionalEmbedding: 3-2        (786,432)\n","|    |    └─ModuleList: 3-3                                  56,702,976\n","|    |    └─LayerNorm: 3-4                                   1,536\n","|    └─PegasusDecoder: 2-3                                   --\n","|    |    └─Embedding: 3-5                                   (recursive)\n","|    |    └─PegasusSinusoidalPositionalEmbedding: 3-6        (786,432)\n","|    |    └─ModuleList: 3-7                                  75,614,208\n","|    |    └─LayerNorm: 3-8                                   1,536\n","├─Linear: 1-2                                                73,807,104\n","=====================================================================================\n","Total params: 281,507,328\n","Trainable params: 279,934,464\n","Non-trainable params: 1,572,864\n","====================================================================================="]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"iC4PZ5UmgzB9","executionInfo":{"status":"ok","timestamp":1619812379867,"user_tz":-180,"elapsed":70,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}}},"source":[""],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ciT4vaYgy4d"},"source":[""]},{"cell_type":"code","metadata":{"id":"3pxuB1v_y5ZW","executionInfo":{"status":"ok","timestamp":1619798429992,"user_tz":-180,"elapsed":58,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}}},"source":["\n","%reload_ext autoreload"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"wOq1Gog7MCKL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619798430317,"user_tz":-180,"elapsed":48,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"2dfc75f5-be55-49cd-845a-76af734bc37a"},"source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":2,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IMXiKS5owZR9","executionInfo":{"status":"ok","timestamp":1619798433626,"user_tz":-180,"elapsed":175,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"6e6dbf2d-3411-4a5d-d227-014145693b16"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Fri Apr 30 19:00:33 2021       \r\n","+-----------------------------------------------------------------------------+\r\n","| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n","|-------------------------------+----------------------+----------------------+\r\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n","|===============================+======================+======================|\r\n","|   0  GeForce RTX 208...  On   | 00000000:2D:00.0 Off |                  N/A |\r\n","|  0%   58C    P2   243W / 300W |   5481MiB / 11016MiB |     96%      Default |\r\n","+-------------------------------+----------------------+----------------------+\r\n","                                                                               \r\n","+-----------------------------------------------------------------------------+\r\n","| Processes:                                                       GPU Memory |\r\n","|  GPU       PID   Type   Process name                             Usage      |\r\n","|=============================================================================|\r\n","|    0      2208      G   /usr/lib/xorg/Xorg                            10MiB |\r\n","|    0     95446      C   python3                                     5459MiB |\r\n","+-----------------------------------------------------------------------------+\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUvi-ZL5MXBz","executionInfo":{"status":"ok","timestamp":1619339350996,"user_tz":-180,"elapsed":2218,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"cb7ffc1c-654d-42db-b203-852da2a8dced"},"source":["from dataset import CnnDmDataset\n","from torch.utils.data import DataLoader\n","\n","dataset_train = CnnDmDataset('train')\n","dataset_val = CnnDmDataset('validation')\n","\n","print()\n","\n","BATCH_SIZE = 3\n","\n","dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=16, collate_fn=CnnDmDataset.collate_fn)\n","dataloader_val = DataLoader(dataset_val, batch_size=2*BATCH_SIZE, shuffle=True, num_workers=8, collate_fn=CnnDmDataset.collate_fn)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:datasets.builder:Reusing dataset cnn_dailymail (/home/kdchernyshev/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/0a01b1abede4f646130574f203de57a293ded8a7a11e3406a539453afdfeb2c0)\n","WARNING:datasets.builder:Reusing dataset cnn_dailymail (/home/kdchernyshev/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/0a01b1abede4f646130574f203de57a293ded8a7a11e3406a539453afdfeb2c0)\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAnFUdngz1Uo","executionInfo":{"status":"ok","timestamp":1619182920053,"user_tz":-180,"elapsed":11038,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"08806f7c-06a4-42f7-f861-30e6d1b83d29"},"source":["%timeit [dataset_train[i] for i in range(100)]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["17.7 ms ± 786 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CsDvBHsX0tkm","executionInfo":{"status":"ok","timestamp":1619184410982,"user_tz":-180,"elapsed":3354,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"9761abb4-0b9d-4810-a549-230d806fee51"},"source":["%timeit [dataset_train[i]['article'] for i in range(100)]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:38: RuntimeWarning: invalid value encountered in reduce\n","  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n","/home/kdchernyshev/sum/dataset.py:34: RuntimeWarning: invalid value encountered in true_divide\n","  node_features = node_features / np.clip(node_features.sum(1), a_min=1, a_max=None)[:,None]\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:38: RuntimeWarning: overflow encountered in reduce\n","  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"],"name":"stderr"},{"output_type":"stream","text":["422 ms ± 101 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZ-vJTLuz5Fg","executionInfo":{"status":"ok","timestamp":1619182891573,"user_tz":-180,"elapsed":4992,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"946aa12d-ec69-4c4f-a0e6-90fdb741bdb0"},"source":["%timeit [dataset_train[i] for i in range(100)]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["604 ms ± 35.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQWFTSGQjTmf","executionInfo":{"status":"ok","timestamp":1619182026232,"user_tz":-180,"elapsed":2795,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"40b615b3-2ba4-4cd0-a9f1-c6ecf426c33d"},"source":["from datasets import load_metric\n","\n","metric_rouge = load_metric('rouge')\n","metric_meteor = load_metric('meteor')\n","# metric_rouge.add_batch(predictions=i['article'], references=i['summary'])\n","# metric_rouge.compute()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to\n","[nltk_data]     /home/kdchernyshev/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6u-tIYClMW9K","executionInfo":{"status":"ok","timestamp":1619299413463,"user_tz":-180,"elapsed":112,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"c35c12b8-fc6c-49be-ea20-77e7d59ae9ff"},"source":["from models.gat import GAT, GraphEncoder\n","\n","gat_model = GAT(num_of_layers=2, num_heads_per_layer=[8, 8], num_features_per_layer=[128, 64, 32])\n","gat_enc_model = GraphEncoder(num_of_layers=2, num_heads_per_layer=[8, 8], num_features_per_layer=[128, 64, 32])\n","\n","data = dataset_train[0]\n","data1 = dataset_train[1]\n","\n","print('data', data['node_features'][None].shape, data['topology'][None].shape)\n","\n","out_nodes_features, edge_index = gat_model(data['node_features'], data['topology'])\n","print(out_nodes_features.shape)\n","\n","print('--')\n","\n","\n","out_nodes_features_batch, edge_index_batch = gat_enc_model([data['node_features'], data1['node_features']], [data['topology'], data1['topology']])\n","print([i.shape for i in out_nodes_features_batch])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["data torch.Size([1, 379, 128]) torch.Size([1, 2, 648])\n","torch.Size([379, 32])\n","--\n","[torch.Size([379, 32]), torch.Size([211, 32])]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecd5cryGARIq","executionInfo":{"status":"ok","timestamp":1619339386873,"user_tz":-180,"elapsed":31003,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"a1b96b23-febb-4b02-d334-a1a1b46a711b"},"source":["from models import get_model\n","\n","tokenizer, model = get_model()\n","model = model.cpu()\n","\n","from torchinfo import summary\n","summary(model, depth=3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["================================================================================\n","Layer (type:depth-idx)                                  Param #\n","================================================================================\n","├─Embedding: 1-1                                        (98,409,472)\n","├─PegasusEncoder: 1-2                                   --\n","|    └─Embedding: 2-1                                   (recursive)\n","|    └─PegasusSinusoidalPositionalEmbedding: 2-2        (1,048,576)\n","|    └─ModuleList: 2-3                                  --\n","|    |    └─PegasusEncoderLayer: 3-1                    (12,596,224)\n","|    |    └─PegasusEncoderLayer: 3-2                    (12,596,224)\n","|    |    └─PegasusEncoderLayer: 3-3                    (12,596,224)\n","|    |    └─PegasusEncoderLayer: 3-4                    (12,596,224)\n","|    └─LayerNorm: 2-4                                   (2,048)\n","├─GraphEncoder: 1-3                                     --\n","|    └─GAT: 2-5                                         --\n","|    |    └─ModuleList: 3-5                             (68,187,136)\n","├─PegasusSuperDecoder: 1-4                              --\n","|    └─Embedding: 2-6                                   (recursive)\n","|    └─PegasusSinusoidalPositionalEmbedding: 2-7        1,048,576\n","|    └─ModuleList: 2-8                                  --\n","|    |    └─PegasusSuperDecoderLayer: 3-6               20,997,120\n","|    |    └─PegasusSuperDecoderLayer: 3-7               20,997,120\n","|    |    └─PegasusSuperDecoderLayer: 3-8               20,997,120\n","|    └─LayerNorm: 2-9                                   2,048\n","├─Linear: 1-5                                           98,409,472\n","================================================================================\n","Total params: 380,483,584\n","Trainable params: 162,451,456\n","Non-trainable params: 218,032,128\n","================================================================================"]},"metadata":{"tags":[]},"execution_count":114}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJFagyhuJcQW","executionInfo":{"status":"ok","timestamp":1619339540344,"user_tz":-180,"elapsed":173,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"f3404911-c558-497c-fd8c-5defa3b96aaf"},"source":["model.__dict__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'training': True,\n"," '_parameters': OrderedDict(),\n"," '_buffers': OrderedDict(),\n"," '_non_persistent_buffers_set': set(),\n"," '_backward_hooks': OrderedDict(),\n"," '_is_full_backward_hook': None,\n"," '_forward_hooks': OrderedDict(),\n"," '_forward_pre_hooks': OrderedDict(),\n"," '_state_dict_hooks': OrderedDict(),\n"," '_load_state_dict_pre_hooks': OrderedDict(),\n"," '_modules': OrderedDict([('shared', Embedding(96103, 1024, padding_idx=0)),\n","              ('encoder',\n","               PegasusEncoder(\n","                 (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n","                 (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n","                 (layers): ModuleList(\n","                   (0): PegasusEncoderLayer(\n","                     (self_attn): PegasusAttention(\n","                       (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                     )\n","                     (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                     (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","                     (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","                     (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                   )\n","                   (1): PegasusEncoderLayer(\n","                     (self_attn): PegasusAttention(\n","                       (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                     )\n","                     (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                     (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","                     (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","                     (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                   )\n","                   (2): PegasusEncoderLayer(\n","                     (self_attn): PegasusAttention(\n","                       (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                     )\n","                     (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                     (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","                     (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","                     (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                   )\n","                   (3): PegasusEncoderLayer(\n","                     (self_attn): PegasusAttention(\n","                       (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                     )\n","                     (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                     (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","                     (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","                     (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                   )\n","                 )\n","                 (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","               )),\n","              ('gat_model',\n","               GraphEncoder(\n","                 (gat): GAT(\n","                   (layers): ModuleList(\n","                     (0): GATLayerImp3(\n","                       (linear_proj): Linear(in_features=128, out_features=4096, bias=False)\n","                       (skip_proj): Linear(in_features=128, out_features=4096, bias=False)\n","                       (leakyReLU): LeakyReLU(negative_slope=0.2)\n","                       (softmax): Softmax(dim=-1)\n","                       (activation): ELU(alpha=1.0)\n","                       (dropout): Dropout(p=0.6, inplace=False)\n","                     )\n","                     (1): GATLayerImp3(\n","                       (linear_proj): Linear(in_features=4096, out_features=8192, bias=False)\n","                       (skip_proj): Linear(in_features=4096, out_features=8192, bias=False)\n","                       (leakyReLU): LeakyReLU(negative_slope=0.2)\n","                       (softmax): Softmax(dim=-1)\n","                       (dropout): Dropout(p=0.6, inplace=False)\n","                     )\n","                   )\n","                 )\n","               )),\n","              ('decoder',\n","               PegasusSuperDecoder(\n","                 (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n","                 (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n","                 (layers): ModuleList(\n","                   (0): PegasusSuperDecoderLayer(\n","                     (self_attn): PegasusAttention(\n","                       (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                     )\n","                     (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                     (encoder_attn): PegasusAttention(\n","                       (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                     )\n","                     (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                     (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","                     (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","                     (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                     (gat_attn): PegasusAttention(\n","                       (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                     )\n","                     (gat_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                   )\n","                   (1): PegasusSuperDecoderLayer(\n","                     (self_attn): PegasusAttention(\n","                       (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                     )\n","                     (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                     (encoder_attn): PegasusAttention(\n","                       (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                     )\n","                     (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                     (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","                     (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","                     (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                     (gat_attn): PegasusAttention(\n","                       (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                     )\n","                     (gat_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                   )\n","                   (2): PegasusSuperDecoderLayer(\n","                     (self_attn): PegasusAttention(\n","                       (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                     )\n","                     (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                     (encoder_attn): PegasusAttention(\n","                       (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                     )\n","                     (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                     (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","                     (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","                     (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                     (gat_attn): PegasusAttention(\n","                       (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                       (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                     )\n","                     (gat_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                   )\n","                 )\n","                 (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","               )),\n","              ('lm_head',\n","               Linear(in_features=1024, out_features=96103, bias=False))]),\n"," 'config': PegasusConfig {\n","   \"_name_or_path\": \"sshleifer/distill-pegasus-cnn-16-4\",\n","   \"activation_dropout\": 0.1,\n","   \"activation_function\": \"relu\",\n","   \"add_bias_logits\": false,\n","   \"add_final_layer_norm\": true,\n","   \"architectures\": [\n","     \"PegasusForConditionalGeneration\"\n","   ],\n","   \"attention_dropout\": 0.1,\n","   \"bos_token_id\": 0,\n","   \"classif_dropout\": 0.0,\n","   \"classifier_dropout\": 0.0,\n","   \"d_model\": 1024,\n","   \"decoder_attention_heads\": 16,\n","   \"decoder_ffn_dim\": 4096,\n","   \"decoder_layerdrop\": 0.0,\n","   \"decoder_layers\": 3,\n","   \"decoder_start_token_id\": 0,\n","   \"dropout\": 0.1,\n","   \"encoder_attention_heads\": 16,\n","   \"encoder_ffn_dim\": 4096,\n","   \"encoder_layerdrop\": 0.0,\n","   \"encoder_layers\": 4,\n","   \"eos_token_id\": 1,\n","   \"extra_pos_embeddings\": 1,\n","   \"force_bos_token_to_be_generated\": false,\n","   \"forced_eos_token_id\": 1,\n","   \"gradient_checkpointing\": false,\n","   \"id2label\": {\n","     \"0\": \"LABEL_0\",\n","     \"1\": \"LABEL_1\",\n","     \"2\": \"LABEL_2\"\n","   },\n","   \"init_std\": 0.02,\n","   \"is_encoder_decoder\": true,\n","   \"label2id\": {\n","     \"LABEL_0\": 0,\n","     \"LABEL_1\": 1,\n","     \"LABEL_2\": 2\n","   },\n","   \"length_penalty\": 0.8,\n","   \"max_length\": 128,\n","   \"max_position_embeddings\": 1024,\n","   \"model_type\": \"pegasus\",\n","   \"normalize_before\": true,\n","   \"normalize_embedding\": false,\n","   \"num_beams\": 8,\n","   \"num_hidden_layers\": 16,\n","   \"pad_token_id\": 0,\n","   \"save_step\": 15,\n","   \"scale_embedding\": true,\n","   \"static_position_embeddings\": true,\n","   \"transformers_version\": \"4.5.1\",\n","   \"use_cache\": true,\n","   \"vocab_size\": 96103\n"," },\n"," 'name_or_path': 'sshleifer/distill-pegasus-cnn-16-4',\n"," 'prepare_inputs_for_generation': <bound method PegasusForConditionalGeneration.prepare_inputs_for_generation of PegasusForConditionalGeneration(\n","   (model): PegasusModel(\n","     (shared): Embedding(96103, 1024, padding_idx=0)\n","     (encoder): PegasusEncoder(\n","       (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n","       (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n","       (layers): ModuleList(\n","         (0): PegasusEncoderLayer(\n","           (self_attn): PegasusAttention(\n","             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","           )\n","           (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","           (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","           (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","           (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","         )\n","         (1): PegasusEncoderLayer(\n","           (self_attn): PegasusAttention(\n","             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","           )\n","           (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","           (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","           (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","           (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","         )\n","         (2): PegasusEncoderLayer(\n","           (self_attn): PegasusAttention(\n","             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","           )\n","           (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","           (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","           (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","           (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","         )\n","         (3): PegasusEncoderLayer(\n","           (self_attn): PegasusAttention(\n","             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","           )\n","           (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","           (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","           (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","           (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","         )\n","       )\n","       (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","     )\n","     (decoder): PegasusDecoder(\n","       (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n","       (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n","       (layers): ModuleList(\n","         (0): PegasusSuperDecoderLayer(\n","           (self_attn): PegasusAttention(\n","             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","           )\n","           (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","           (encoder_attn): PegasusAttention(\n","             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","           )\n","           (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","           (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","           (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","           (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","           (gat_attn): PegasusAttention(\n","             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","           )\n","           (gat_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","         )\n","         (1): PegasusSuperDecoderLayer(\n","           (self_attn): PegasusAttention(\n","             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","           )\n","           (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","           (encoder_attn): PegasusAttention(\n","             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","           )\n","           (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","           (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","           (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","           (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","           (gat_attn): PegasusAttention(\n","             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","           )\n","           (gat_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","         )\n","         (2): PegasusSuperDecoderLayer(\n","           (self_attn): PegasusAttention(\n","             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","           )\n","           (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","           (encoder_attn): PegasusAttention(\n","             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","           )\n","           (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","           (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","           (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","           (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","           (gat_attn): PegasusAttention(\n","             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","           )\n","           (gat_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","         )\n","       )\n","       (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","     )\n","   )\n","   (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n"," )>}"]},"metadata":{"tags":[]},"execution_count":117}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iq1iuyvbyB-t","executionInfo":{"status":"ok","timestamp":1619305229862,"user_tz":-180,"elapsed":871,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"29882f91-ef6a-4c51-e822-cc5d218e91fb"},"source":["import torch\n","import torch.nn.functional as F\n","\n","data = dataset_train[0]\n","data1 = dataset_train[1]\n","input_tokens = tokenizer([data['article'], data1['article']], truncation=True, padding='longest', return_tensors=\"pt\")\n","target_tokens = tokenizer([data['summary'], data1['summary']], truncation=True, padding='longest', return_tensors=\"pt\")\n","\n","out = model(**input_tokens, decoder_input_ids=target_tokens.input_ids, input_nodes_embeddings=[data['node_features'], data1['node_features']], input_edges=[data['topology'], data1['topology']])\n","print(tokenizer.batch_decode(torch.argmax(F.softmax(out.logits, dim=-1), dim=-1)))\n","# print(tokenizer.batch_decode(model.predict(**input_tokens)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["encoder_hidden_states torch.Size([2, 1024, 1024])\n","encoder_attention_mask torch.Size([2, 1024])\n","gat_hidden_states torch.Size([2, 379, 1024])\n","gat_attention_mask torch.Size([2, 379])\n","['Syrian  I has to to the to the House to andThis\\'t be\" we to to\" The has a letter to the House ofs House on Senate on  The has make out approval for Saturday issues: the,. The of to be how the weapons used by and just</s>, the the-S. president  </s></s>', \" Bolt the in in     Theing:' winxxs and and in </s>-s the end, the and </s>'- for the's finalthxm and  </s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\"]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A1Y6AGjF32JJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"krHujjK6-Rbz","executionInfo":{"status":"ok","timestamp":1619190130549,"user_tz":-180,"elapsed":78,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"09ac38e4-bd4c-481e-b2d7-af04922d74c8"},"source":["from openie import get_triplets\n","import torch\n","\n","triplets = get_triplets(data['summary'])\n","\n","nodes = set()\n","for t in triplets:\n","    nodes.update(t)\n","nodes = {n: i for i, n in enumerate(nodes)}\n","\n","def _get_nodes_features(nodes, enc_dim=1024, device='cuda'):\n","    emb = torch.zeros(size=(len(nodes), enc_dim))\n","\n","    texts = [text for text, i in nodes.items()]\n","\n","    input_tokens = tokenizer(texts, truncation=True, padding='longest', return_tensors=\"pt\")\n","    input_tokens = {k: v.to(device) for k, v in input_tokens.items()}\n","\n","    with torch.no_grad():\n","        out = model.encoder(input_tokens['input_ids'], input_tokens['attention_mask'])\n","\n","    for k, v in input_tokens.items(): del v\n","\n","    # del out\n","\n","    return out.last_hidden_state\n","        \n","_get_nodes_features(nodes)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BaseModelOutput(last_hidden_state=tensor([[[ 0.2346, -0.0819, -0.0281,  ..., -0.0959, -0.6350, -0.0228],\n","         [-0.0315, -0.0278,  0.1546,  ...,  0.0752,  0.0322,  0.0144],\n","         [ 0.0681, -0.0955,  0.0784,  ...,  0.1872, -0.0754,  0.1290],\n","         ...,\n","         [ 0.0288, -0.0996,  0.0833,  ...,  0.1636, -0.0811,  0.1207],\n","         [ 0.0259, -0.0962,  0.0886,  ...,  0.1305, -0.0849,  0.1317],\n","         [ 0.0228, -0.0887,  0.0967,  ...,  0.1045, -0.0515,  0.1379]],\n","\n","        [[ 0.0454, -0.0306,  0.0409,  ...,  0.0661, -0.0218,  0.0676],\n","         [-0.0288, -0.0265,  0.1581,  ...,  0.1106,  0.0576,  0.0338],\n","         [ 0.0790, -0.0706,  0.0901,  ...,  0.2093, -0.0231,  0.1510],\n","         ...,\n","         [ 0.0506, -0.0821,  0.0948,  ...,  0.1686, -0.0789,  0.1438],\n","         [ 0.0237, -0.0705,  0.0938,  ...,  0.1311, -0.0561,  0.1128],\n","         [ 0.0231, -0.0655,  0.0949,  ...,  0.1354, -0.0537,  0.1188]],\n","\n","        [[ 0.0043, -0.0469, -0.0045,  ...,  0.2118,  0.2374,  0.0231],\n","         [-0.0631, -0.0247,  0.1554,  ...,  0.0853,  0.0933, -0.0067],\n","         [ 0.0156, -0.0546,  0.0911,  ...,  0.1521, -0.0333,  0.0832],\n","         ...,\n","         [ 0.0030, -0.0737,  0.1002,  ...,  0.1477, -0.0289,  0.1083],\n","         [ 0.0140, -0.0654,  0.1084,  ...,  0.1478, -0.0228,  0.1131],\n","         [ 0.0166, -0.0599,  0.1085,  ...,  0.1549, -0.0272,  0.1193]],\n","\n","        ...,\n","\n","        [[ 0.1936, -0.0863, -0.0346,  ..., -0.1294, -0.5731,  0.1142],\n","         [ 0.1349, -0.0583,  0.1058,  ...,  0.1837, -0.0088,  0.0599],\n","         [ 0.1646, -0.0138, -0.0260,  ...,  0.2058, -0.3625,  0.0731],\n","         ...,\n","         [-0.0064, -0.0580, -0.0821,  ...,  0.1899, -0.3082, -0.1332],\n","         [ 0.0413, -0.0284,  0.1586,  ...,  0.0075,  0.1096,  0.0223],\n","         [ 0.0460, -0.0964,  0.0882,  ...,  0.0723,  0.0218,  0.1252]],\n","\n","        [[ 0.2107, -0.0849, -0.0601,  ...,  0.3035,  0.0138,  0.0513],\n","         [ 0.0092, -0.0383,  0.1452,  ...,  0.1210,  0.0330, -0.0595],\n","         [ 0.0793, -0.0884,  0.0887,  ...,  0.1419, -0.1414,  0.0811],\n","         ...,\n","         [ 0.0544, -0.0933,  0.1017,  ...,  0.1977, -0.1455,  0.0916],\n","         [ 0.0471, -0.0808,  0.1096,  ...,  0.1700, -0.1461,  0.0721],\n","         [ 0.0479, -0.0721,  0.1092,  ...,  0.1712, -0.1563,  0.0778]],\n","\n","        [[-0.1017, -0.0140, -0.0343,  ..., -0.2061, -0.1599,  0.0424],\n","         [-0.0797, -0.0030,  0.1480,  ...,  0.0836,  0.0897, -0.0062],\n","         [ 0.0036, -0.0443,  0.0870,  ...,  0.1067,  0.0143,  0.0671],\n","         ...,\n","         [-0.0390, -0.0536,  0.0823,  ...,  0.1118, -0.0058,  0.1041],\n","         [-0.0404, -0.0446,  0.0868,  ...,  0.1041,  0.0104,  0.1052],\n","         [-0.0327, -0.0374,  0.0897,  ...,  0.1045,  0.0134,  0.1123]]],\n","       device='cuda:0'), hidden_states=None, attentions=None)"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DtEWfVI3cJU","executionInfo":{"status":"ok","timestamp":1619185439287,"user_tz":-180,"elapsed":104,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"4404e54e-940e-41d5-8696-6623aec1d5ca"},"source":["model.encoder(**input_tokens)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BaseModelOutput(last_hidden_state=tensor([[[ 0.0544, -0.0105,  0.0110,  ...,  0.0767, -0.0407, -0.0432],\n","         [ 0.0256,  0.0374, -0.0972,  ...,  0.1123,  0.0054, -0.0293],\n","         [ 0.2315,  0.0837, -0.0035,  ..., -0.1696,  0.0024, -0.0686],\n","         ...,\n","         [-0.2165,  0.1029, -0.0683,  ..., -0.2700, -0.1096,  0.0844],\n","         [-0.0412,  0.0570,  0.0067,  ...,  0.1963, -0.1248,  0.0603],\n","         [-0.0488,  0.0173,  0.1425,  ...,  0.0509,  0.1813,  0.0235]]],\n","       device='cuda:0'), hidden_states=None, attentions=None)"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":784},"id":"58o7m2Z3PWp_","executionInfo":{"status":"error","timestamp":1619183635153,"user_tz":-180,"elapsed":802,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"457f7633-1c94-4724-e70a-9d8796b580c5"},"source":["import torch\n","import torch.nn.functional as F\n","data = dataset_train[0]\n","input_tokens = tokenizer(data['article'], truncation=True, padding='longest', return_tensors=\"pt\")\n","target_tokens = tokenizer(data['summary'], truncation=True, padding='longest', return_tensors=\"pt\")\n","\n","tokenizer.batch_decode(torch.argmax(F.softmax(model(**input_tokens, decoder_input_ids=target_tokens.input_ids).logits, dim=-1), dim=-1))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-304e76991617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtarget_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'longest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/sum/models/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, encoder_outputs, output_attentions, output_hidden_states, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         return Seq2SeqLMOutput(\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Tensor for argument #3 'mat2' is on CPU, but expected it to be on GPU (while checking arguments for addmm)"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ZQCvIssX35l","executionInfo":{"status":"ok","timestamp":1619126852570,"user_tz":-180,"elapsed":7366,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"437d1704-d546-4e1a-d1f6-833afca9e6b2"},"source":["tokenizer.batch_decode(model.predict(**input_tokens))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<pad> The has to be by the the the House House House is to be for for for first to have been by the House wants to hold on how will be by President President President Obama has to take, on issues</s>']"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UobNqAvzBoZg","executionInfo":{"status":"ok","timestamp":1619126583632,"user_tz":-180,"elapsed":8444,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"b6256fed-0374-489d-a3ec-d6a52897f2e8"},"source":["data = dataset_train[0]\n","input_tokens = tokenizer(data['article'], truncation=True, padding='longest', return_tensors=\"pt\")\n","target_tokens = tokenizer(data['summary'], truncation=True, padding='longest', return_tensors=\"pt\")\n","\n","tokenizer.batch_decode(model.generate(**input_tokens, do_sample=True, repetition_penalty=2.0, min_length=42, max_length=100, no_repeat_ngram_size=3, num_beams=4))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<pad> President Obama has to be by the the the House House House is to hold on the the security and officials have been by the House wants to make for for for first to be of the the North to protect, on issues</s>']"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"RgvW7DvkN1N8"},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.nn import CrossEntropyLoss\n","import torch.nn.functional as F\n","from tqdm.auto import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cMyyzUcyMLUd"},"source":["from common import get_criterion_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wagfmc0ZI26S","executionInfo":{"status":"ok","timestamp":1619113836905,"user_tz":-180,"elapsed":3124,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"1ca189f7-b116-413b-e0db-6e656c6a7a69"},"source":["import neptune.new as neptune\n","\n","run = neptune.init(project='k4black/diploma-sum', api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzZDliYzEyZS1hOWVkLTQ1ZDQtOThlYS1jNDhhOTFjMGQ4ZjAifQ==')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["https://app.neptune.ai/k4black/diploma-sum/e/SUM-20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["7ba876e64089493a99599bed9ccf6cc0","833a6bd4e7314b669eb054aff23d9ebb","87d10b37f9574ba8a8cecf6b800cb8ef","79d274dbe66d40af9f81b4fc2ff8277d","fa1b6b3d99b24ba5a6b8f606a5e86af0","45db43ce1ddb47cda541d2f462c51237","d3197f7fe2a24cb7bc212886866ee1d6","b3503afdf2274796b2d701223b7b04f4","3b6ba7505a294947a0818510ac1f9b6c","72a6045fae544b06aaf3fd4c996d6d7a","c3b43a4839b94b8bb3420af86cc43081","5e79f32871b147719b9cee2501d28fc1","45e5a82e70574f85a366dd71f34cf9e4","1729ab4e39fc4e3c9bc04554b8ff0964","c371c5f5188a4371a71a955ef3a7c8f4","c68ce677df80410792e71b6909122d6a"]},"id":"DkmGKTIzN1Kq","executionInfo":{"status":"error","timestamp":1619113868609,"user_tz":-180,"elapsed":22279,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"707deada-64f2-429b-aec8-e6a4f767cb05"},"source":["from transformers import AdamW, get_cosine_schedule_with_warmup\n","\n","LR = 1e-4\n","EPOCHES = 1\n","DEVICE = 'cuda:1'\n","MIN_GEN = 42\n","# DEVICE = 'cpu'\n","model = pegasus_model\n","tokenizer = pegasus_tokenizer\n","\n","model = model.to(DEVICE)\n","model = nn.DataParallel(model, device_ids=[1, 4, 5, 6]).to(DEVICE)\n","# torch.distributed.init_process_group(backend='nccl', init_method='env://')\n","# model = nn.parallel.DistributedDataParallel(model, device_ids=[1, 3, 4, 5, 6]).to(DEVICE)\n","\n","scaler = torch.cuda.amp.GradScaler()  # mixed precision \n","\n","criterion = lambda x, y, m: get_criterion_loss(x, y, m)\n","optimizer = AdamW(model.parameters(), lr=LR)\n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=80000)\n","\n","\n","run[\"parameters\"] = {\"learning_rate\": LR,\n","                     \"model\": \"pegasus\",\n","                     \"encoders\": \"16\",\n","                     \"decoders\": \"4\",\n","                     \"optimizer\": type(optimizer).__name__}\n","\n","for e in tqdm(range(EPOCHES), desc=\"epoch\", leave=False):\n","    train_runnig_loss = 0\n","    train_runnig_num = 0\n","    for i, batch in tqdm(enumerate(dataloader_train), total=len(dataloader_train), desc=\"train\", leave=False):\n","        optimizer.zero_grad()\n","\n","        input_tokens = tokenizer(batch['article'], truncation=True, padding='longest', return_tensors=\"pt\")\n","        target_tokens = tokenizer(batch['summary'], truncation=True, padding='longest', return_tensors=\"pt\")\n","\n","        input_tokens = {k: v.to(DEVICE) for k, v in input_tokens.items()}\n","        target_tokens = {k: v.to(DEVICE) for k, v in target_tokens.items()}\n","\n","        with torch.cuda.amp.autocast():\n","            outputs = model(**input_tokens, decoder_input_ids=target_tokens['input_ids'])\n","            loss = criterion(outputs.logits, target_tokens['input_ids'], target_tokens['attention_mask'])\n","\n","        train_runnig_loss += loss.item()\n","        train_runnig_num += len(batch['article'])\n","\n","        run[\"train/loss\"].log(loss.item() / len(batch['article']))\n","\n","        if i % 1 == 0:\n","            print('---')\n","            print(\"  running loss:\", train_runnig_loss / train_runnig_num)\n","            run[\"train/running-loss\"].log(train_runnig_loss / train_runnig_num)\n","\n","            # if i % 64 == 0:\n","            #     with torch.no_grad():\n","            #         out = tokenizer.batch_decode(torch.argmax(F.softmax(outputs.logits, dim=-1), dim=-1))\n","            #         print('-> ', out)\n","            #         # print('vs ', batch['summary'])\n","            #         print('vs ', tokenizer.batch_decode(target_tokens['input_ids']))\n","            #         print('gn ', tokenizer.batch_decode(model.module.generate(**input_tokens, min_length=MIN_GEN, do_sample=True, num_beams=3).to('cpu')) )\n","\n","            \n","            print('---')\n","\n","        scaler.scale(loss).backward()  #\n","        scaler.step(optimizer)  # \n","        # loss.backward()\n","        # optimizer.step()\n","\n","        scheduler.step()\n","        scaler.update()\n","\n","        for k, v in input_tokens.items(): del v\n","        for k, v in target_tokens.items(): del v\n","\n","        if i > 100:\n","            break\n","                \n","    val_runnig_loss = 0\n","    val_runnig_num = 0\n","    for i, batch in tqdm(enumerate(dataloader_val), total=len(dataloader_val), desc=\"val\", leave=False):\n","        with torch.no_grad():\n","            input_tokens = tokenizer(batch['article'], truncation=True, padding='longest', return_tensors=\"pt\")\n","            target_tokens = tokenizer(batch['summary'], truncation=True, padding='longest', return_tensors=\"pt\")\n","\n","            input_tokens = {k: v.to(DEVICE) for k, v in input_tokens.items()}\n","            target_tokens = {k: v.to(DEVICE) for k, v in target_tokens.items()}\n","\n","            outputs = model(**input_tokens, decoder_input_ids=target_tokens['input_ids'])\n","            loss = criterion(outputs.logits, target_tokens['input_ids'], target_tokens['attention_mask'])\n","\n","            val_runnig_loss += loss.item()\n","            val_runnig_num += len(batch['article'])\n","\n","            # out_summary = tokenizer.batch_decode(torch.argmax(F.softmax(outputs.logits, dim=-1), dim=-1))\n","            out_summary = tokenizer.batch_decode(model.module.generate(**input_tokens, min_length=MIN_GEN, do_sample=True, num_beams=3).to('cpu'))\n","            metric_rouge.add_batch(predictions=out_summary, references=batch['summary'])\n","\n","        for k, v in input_tokens.items(): del v\n","        for k, v in target_tokens.items(): del v\n","\n","        if i > 100:\n","            break\n","    \n","    print('------------------------------')\n","    print(\"  running loss val:\", val_runnig_loss / val_runnig_num)\n","    rouge = metric_rouge.compute()\n","    print(rouge)\n","    print('------------------------------')\n","\n","    run[\"val/rouge1\"] = rouge['rouge1'].mid.fmeasure\n","    run[\"val/rouge2\"] = rouge['rouge2'].mid.fmeasure\n","    run[\"val/rougeLsum\"] = rouge['rougeLsum'].mid.fmeasure\n","    run[\"val/loss\"] = val_runnig_loss / val_runnig_num\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["HBox(children=(FloatProgress(value=0.0, description='epoch', max=1.0, style=ProgressStyle(description_width='i…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ba876e64089493a99599bed9ccf6cc0"}},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["HBox(children=(FloatProgress(value=0.0, description='train', max=71779.0, style=ProgressStyle(description_widt…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b6ba7505a294947a0818510ac1f9b6c"}},"metadata":{"tags":[]}},{"output_type":"stream","text":["---\n","  running loss: 6.196994304656982\n","---\n","---\n","  running loss: 6.640599966049194\n","---\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-a2a5dc353bc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, *grad_outputs)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mReduceAddCoalesced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, destination, num_inputs, *grads)\u001b[0m\n\u001b[1;32m     43\u001b[0m         grads_ = [grads[i:i + num_inputs]\n\u001b[1;32m     44\u001b[0m                   for i in range(0, len(grads), num_inputs)]\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_add_coalesced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/parallel/comm.py\u001b[0m in \u001b[0;36mreduce_add_coalesced\u001b[0;34m(inputs, destination, buffer_size)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mflat_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_flatten_dense_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (num_gpus,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mflat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_unflatten_dense_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# The unflattened tensors do not share storage, and we don't expose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/parallel/comm.py\u001b[0m in \u001b[0;36mreduce_add\u001b[0;34m(inputs, destination)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnccl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mnccl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 1; 7.80 GiB total capacity; 5.64 GiB already allocated; 363.44 MiB free; 6.41 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"sty2fXKoN1Ha"},"source":["run.stop()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEraofu8N1ES","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619008928522,"user_tz":-180,"elapsed":124,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"f9220f78-9109-4892-a552-b453d22ea2a5"},"source":["rouge['rouge1'].mid.fmeasure"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.14900834094406204"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"OUKr2of-N2bi"},"source":[""]},{"cell_type":"code","metadata":{"id":"oL1GFD9HhThj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GjFyY-DAhTeh"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qpoHftgGQfVy","executionInfo":{"status":"ok","timestamp":1618773983341,"user_tz":-180,"elapsed":54,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"206bce2f-e7d4-43f6-d325-931b7cf78bce"},"source":["input_tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[1027, 1352,    1]]), 'attention_mask': tensor([[1, 1, 1]])}"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"_LrJg6uHMW6k"},"source":["import torch\n","import torch.nn as nn\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, text_encoder, gat_encoder):\n","        super().__init__()\n","        self.text_encoder = encoder\n","        self.gat_encoder = gat_encoder\n","\n","    def forward(self, input_ids, attention_mask):\n","        return self.text_encoder(**kwargs)\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, base_model):\n","        super().__init__()\n","        self.base_model = base_model\n","\n","    def forward(self, **kwargs):\n","        return self.base_model(**kwargs)\n","\n","class Model(nn.Module):\n","    def __init__(self, base_model):\n","        super().__init__()\n","        self.lm_head = Linear(in_features=1024, out_features=96103, bias=False)\n","\n","    def forward(self, **kwargs):\n","        return self.base_model(**kwargs)\n","    \n","\n","encoder = Encoder(pegasus_model.encoder)\n","decoder = Decoder(pegasus_model.decoder)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dqhWLcPvbCFm"},"source":["\n","model.train_model(train_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":717},"id":"x7yov086P6HA","executionInfo":{"status":"error","timestamp":1618921030993,"user_tz":-180,"elapsed":134,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"80ef0ff4-ab15-4978-c9d6-159fbd6164e4"},"source":["model.generate(**input_tokens)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-4d2865d03126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, **model_kwargs)\u001b[0m\n\u001b[1;32m   1001\u001b[0m                 \u001b[0moutput_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m             )\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, **model_kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mcur_len\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# prepare model inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m             \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py\u001b[0m in \u001b[0;36mprepare_inputs_for_generation\u001b[0;34m(self, input_ids, past, attention_mask, use_cache, encoder_outputs, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;34m\"decoder_input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m             \u001b[0;34m\"past_key_values\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past_key_values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m             \u001b[0;34m\"use_cache\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         }\n","\u001b[0;31mKeyError\u001b[0m: 'past_key_values'"]}]},{"cell_type":"code","metadata":{"id":"zSJBaEH0POzm"},"source":["pegasus_model.decoder()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYcjjY33MWo3","executionInfo":{"status":"ok","timestamp":1618921026209,"user_tz":-180,"elapsed":146,"user":{"displayName":"Константин Чернышев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgholgC9Y1ddWhnS5FfjjfvI0z2qOowPUiSd1kuw=s64","userId":"11654258463184354215"}},"outputId":"58bc5ecd-c44e-4e1f-98ac-7ca4085ef047"},"source":["input_tokens = pegasus_tokenizer(['Some text'], truncation=True, padding='longest', return_tensors=\"pt\")\n","\n","encoder(**input_tokens).last_hidden_state"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.0034,  0.0632,  0.1504,  ...,  0.1808, -0.0844,  0.0342],\n","         [-0.1237,  0.0421,  0.1656,  ...,  0.1279, -0.3230,  0.0770],\n","         [ 0.0231, -0.0155,  0.0965,  ...,  0.0193,  0.0016, -0.0204]]],\n","       grad_fn=<NativeLayerNormBackward>)"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"V0PRH64rPD0K"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NXUxW6AEdoqP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8CXdFZHdonI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iZsYqWnPdoj5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ylXgrOvpdog4"},"source":[""],"execution_count":null,"outputs":[]}]}